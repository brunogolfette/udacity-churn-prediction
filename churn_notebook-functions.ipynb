{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_roc_curve, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./data/bank_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_data(pth):\n",
    "    '''\n",
    "    returns dataframe for the csv found at pth\n",
    "    \n",
    "    input:\n",
    "            pth: a path to the csv\n",
    "    output:\n",
    "            df: pandas dataframe\n",
    "    '''\t\n",
    "    df = pd.read_csv(pth)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def perform_eda(df):\n",
    "    '''\n",
    "    Perform exploratory data analysis (EDA) on the dataframe and save figures to the images/eda directory.\n",
    "    \n",
    "    Input:\n",
    "        df: pandas DataFrame - the dataframe on which EDA will be performed.\n",
    "    \n",
    "    Output:\n",
    "        None - figures are saved to files.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        # Convert 'Attrition_Flag' into a binary 'Churn' column if needed\n",
    "        if 'Churn' not in df.columns:\n",
    "            df['Churn'] = df['Attrition_Flag'].apply(lambda val: 0 if val == \"Existing Customer\" else 1)\n",
    "\n",
    "        # Path to the directory where the graphs will be saved\n",
    "        save_path = './images/eda/'\n",
    "\n",
    "        # Check if the directory exists; if not, create it.\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        # Function to save histogram of 'Churn'\n",
    "        def save_churn_hist():\n",
    "            plt.figure(figsize=(20,10))\n",
    "            df['Churn'].hist()\n",
    "            file_path = os.path.join(save_path, 'histogram_churn.png')\n",
    "            plt.savefig(file_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Function to save histogram of 'Customer_Age'\n",
    "        def save_customer_age_hist():\n",
    "            plt.figure(figsize=(20,10))\n",
    "            df['Customer_Age'].hist()\n",
    "            file_path = os.path.join(save_path, 'customer_age_hist.png')\n",
    "            plt.savefig(file_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Function to save bar plot of 'Marital_Status'\n",
    "        def save_marital_status_bar():\n",
    "            plt.figure(figsize=(20,10))\n",
    "            df['Marital_Status'].value_counts(normalize=True).plot(kind='bar')\n",
    "            file_path = os.path.join(save_path, 'marital_status_bar.png')\n",
    "            plt.savefig(file_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Function to save histogram of 'Total_Trans_Ct' with KDE\n",
    "        def save_transactions_hist():\n",
    "            plt.figure(figsize=(20,10))\n",
    "            sns.histplot(df['Total_Trans_Ct'], stat='density', kde=True)\n",
    "            file_path = os.path.join(save_path, 'total_trans_hist.png')\n",
    "            plt.savefig(file_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Function to save heatmap of correlations\n",
    "        def save_correlation_heatmap():\n",
    "            plt.figure(figsize=(20,10))\n",
    "            sns.heatmap(df.corr(), annot=False, cmap='Dark2_r', linewidths=2)\n",
    "            file_path = os.path.join(save_path, 'correlation_heatmap.png')\n",
    "            plt.savefig(file_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Call functions to generate and save plots\n",
    "        save_churn_hist()\n",
    "        save_customer_age_hist()\n",
    "        save_marital_status_bar()\n",
    "        save_transactions_hist()\n",
    "        save_correlation_heatmap()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during EDA: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_helper(df, category_lst, response='Churn'):\n",
    "    '''\n",
    "    Helper function to turn each categorical column into a new column with\n",
    "    the proportion of the response (e.g., churn) for each category.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame - The dataframe to process.\n",
    "        category_lst: list - A list of column names that contain categorical features.\n",
    "        response: str - The name of the response column (default is 'Churn').\n",
    "\n",
    "    Output:\n",
    "        df: pandas DataFrame - The dataframe with new columns for each categorical variable encoded.\n",
    "    '''\n",
    "\n",
    "    def encode_column(column):\n",
    "        '''\n",
    "        Encodes a single categorical column using mean of the response variable.\n",
    "\n",
    "        Input:\n",
    "            column: str - The name of the column to encode.\n",
    "\n",
    "        Output:\n",
    "            None - The function directly modifies the dataframe in place.\n",
    "        '''\n",
    "        # Group by the category and calculate the mean of the response\n",
    "        group_means = df.groupby(column).mean()[response]\n",
    "\n",
    "        # Map the mean response to each entry in the dataframe\n",
    "        encoded_column_name = f\"{column}_{response}\"\n",
    "        df[encoded_column_name] = df[column].map(group_means)\n",
    "\n",
    "    # Apply encoding to each category in the list\n",
    "    for category in category_lst:\n",
    "        encode_column(category)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'df' is your DataFrame and it includes the 'Gender', 'Education_Level', 'Marital_Status',\n",
    "# 'Income_Category', and 'Card_Category' columns that you want to encode.\n",
    "category_list = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def perform_feature_engineering(df, response):\n",
    "    '''\n",
    "    Perform feature engineering to prepare the dataset for machine learning models\n",
    "    by selecting specified columns and splitting the data into training and testing sets.\n",
    "    \n",
    "    Input:\n",
    "        df: pandas DataFrame - The dataframe to process.\n",
    "        response: str - The name of the response column to be used as the target variable.\n",
    "    \n",
    "    Output:\n",
    "        X_train: DataFrame - Training feature data.\n",
    "        X_test: DataFrame - Testing feature data.\n",
    "        y_train: Series - Training target data.\n",
    "        y_test: Series - Testing target data.\n",
    "        \n",
    "    Raises:\n",
    "        Exception: Captures and logs general exceptions if the feature engineering process fails.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        # Extracting the response variable\n",
    "        y = df[response]\n",
    "        \n",
    "        # Define the columns to keep in the feature matrix X\n",
    "        keep_cols = ['Customer_Age', 'Dependent_count', 'Months_on_book',\n",
    "                     'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
    "                     'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
    "                     'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
    "                     'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio',\n",
    "                     'Gender_Churn', 'Education_Level_Churn', 'Marital_Status_Churn', \n",
    "                     'Income_Category_Churn', 'Card_Category_Churn']\n",
    "        \n",
    "        # Ensure all specified columns are in the DataFrame, to avoid KeyError\n",
    "        filtered_cols = [col for col in keep_cols if col in df.columns]\n",
    "        \n",
    "        # Creating the feature matrix X with the specified columns\n",
    "        X = df[filtered_cols]\n",
    "        \n",
    "        # Splitting the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: One or more columns not found in the dataframe: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Trains logistic regression and random forest models, evaluates them with classification reports,\n",
    "    saves the models to disk, and returns training and testing predictions.\n",
    "\n",
    "    Input:\n",
    "        X_train: DataFrame - Training feature data.\n",
    "        X_test: DataFrame - Testing feature data.\n",
    "        y_train: Series - Training target data.\n",
    "        y_test: Series - Testing target data.\n",
    "\n",
    "    Output:\n",
    "        Tuple - Contains y_train, y_test, y_train_preds_lr, y_train_preds_rf, y_test_preds_lr, y_test_preds_rf\n",
    "    '''\n",
    "    try:\n",
    "        # Ensure the models directory exists\n",
    "        models_dir = './models/'\n",
    "        if not os.path.exists(models_dir):\n",
    "            os.makedirs(models_dir)\n",
    "\n",
    "        # Initialize the models\n",
    "        lrc = LogisticRegression(solver='lbfgs', max_iter=3000)\n",
    "        rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        # Set up parameter grid for Random Forest\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'max_depth': [4, 5],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }\n",
    "\n",
    "        # GridSearch for optimal parameters in Random Forest\n",
    "        cv_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "        cv_rfc.fit(X_train, y_train)\n",
    "\n",
    "        # Fit Logistic Regression\n",
    "        lrc.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_train_preds_rf = cv_rfc.best_estimator_.predict(X_train)\n",
    "        y_test_preds_rf = cv_rfc.best_estimator_.predict(X_test)\n",
    "        y_train_preds_lr = lrc.predict(X_train)\n",
    "        y_test_preds_lr = lrc.predict(X_test)\n",
    "\n",
    "        # Save models\n",
    "        joblib.dump(cv_rfc.best_estimator_, os.path.join(models_dir, 'rfc_model.pkl'))\n",
    "        joblib.dump(lrc, os.path.join(models_dir, 'logistic_model.pkl'))\n",
    "\n",
    "        return (y_train, y_test, y_train_preds_lr, y_train_preds_rf, y_test_preds_lr, y_test_preds_rf)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example of how you might call this function\n",
    "# Assume X_train, X_test, y_train, y_test are defined from your data preparation steps\n",
    "# results = train_models(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc, RocCurveDisplay\n",
    "\n",
    "\n",
    "def classification_report_image(y_train, y_test, y_train_preds_lr, y_train_preds_rf, y_test_preds_lr, y_test_preds_rf):\n",
    "    '''\n",
    "    Produces classification report for training and testing results and stores report as image in images folder.\n",
    "    \n",
    "    Input:\n",
    "        y_train: training response values\n",
    "        y_test: test response values\n",
    "        y_train_preds_lr: training predictions from logistic regression\n",
    "        y_train_preds_rf: training predictions from random forest\n",
    "        y_test_preds_lr: test predictions from logistic regression\n",
    "        y_test_preds_rf: test predictions from random forest\n",
    "\n",
    "    Output:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    def save_classification_report(y_true, y_pred, model_name, dataset_type):\n",
    "        '''\n",
    "        Saves the classification report as an image.\n",
    "        \n",
    "        Input:\n",
    "            y_true: actual target values\n",
    "            y_pred: predictions from model\n",
    "            model_name: name of the model (e.g., 'logistic_regression', 'random_forest')\n",
    "            dataset_type: type of data (e.g., 'train', 'test')\n",
    "        \n",
    "        Output:\n",
    "            None - saves an image file of the classification report\n",
    "        '''\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        ax.axis('off')\n",
    "        ax.text(0, 0, f\"{model_name.upper()} {dataset_type.upper()} REPORT:\\n\" + \n",
    "                classification_report(y_true, y_pred), fontdict={'fontsize': 14}, va='top')\n",
    "        filepath = f'./images/results/{model_name}_{dataset_type}_report.png'\n",
    "        plt.savefig(filepath)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_roc_curves():\n",
    "        '''\n",
    "        Plots ROC curves for both models and saves as an image.\n",
    "        '''\n",
    "        try:\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            ax = plt.gca()\n",
    "            lrc = joblib.load('./models/logistic_model.pkl')\n",
    "            rfc_best = joblib.load('./models/rfc_model.pkl')\n",
    "\n",
    "            models = [\n",
    "                ('Random Forest',rfc_best , y_test),\n",
    "                ('Logistic Regression', lrc, y_test)\n",
    "                \n",
    "            ]\n",
    "\n",
    "            for name, model, preds in models:\n",
    "                fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=name).plot(ax=ax)\n",
    "\n",
    "            plt.savefig('./images/results/roc_curves.png')\n",
    "            plt.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while plotting ROC curves: {e}\")\n",
    "\n",
    "    # Call the function to save classification reports\n",
    "    save_classification_report(y_train, y_train_preds_lr, 'logistic_regression', 'train')\n",
    "    save_classification_report(y_test, y_test_preds_lr, 'logistic_regression', 'test')\n",
    "    save_classification_report(y_train, y_train_preds_rf, 'random_forest', 'train')\n",
    "    save_classification_report(y_test, y_test_preds_rf, 'random_forest', 'test')\n",
    "\n",
    "    # Plot and save the ROC curves\n",
    "    plot_roc_curves()\n",
    "\n",
    "    # Assume model saving and loading functions are correctly defined elsewhere\n",
    "\n",
    "classification_report_image(y_train, y_test, y_train_preds_lr, y_train_preds_rf, y_test_preds_lr, y_test_preds_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    '''\n",
    "    Safely loads a machine learning model from the specified path.\n",
    "    \n",
    "    Input:\n",
    "        model_path: str - Path to the machine learning model file.\n",
    "    \n",
    "    Output:\n",
    "        model - Loaded model if successful, None otherwise.\n",
    "    '''\n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model from {model_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def feature_importance_plot(model, X_data, output_pth):\n",
    "    '''\n",
    "    Creates and stores both traditional feature importances and SHAP summary plots for tree-based models.\n",
    "    \n",
    "    Input:\n",
    "        model: The trained tree-based model object (e.g., RandomForest, XGBoost).\n",
    "        X_data: pandas DataFrame - The feature data used for the analysis.\n",
    "        output_pth: str - The directory path where the feature importance plots will be saved.\n",
    "    \n",
    "    Output:\n",
    "        None - The function saves feature importance plots in the specified output path.\n",
    "    '''\n",
    "    def ensure_dir(directory):\n",
    "        ''' Ensure the directory exists. If not, create it. '''\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "    def plot_feature_importances():\n",
    "        ''' Plot and save traditional feature importances. '''\n",
    "        try:\n",
    "            importances = model.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            names = [X_data.columns[i] for i in indices]\n",
    "\n",
    "            plt.figure(figsize=(20, 5))\n",
    "            plt.title(\"Feature Importance\")\n",
    "            plt.ylabel('Importance')\n",
    "            plt.bar(range(X_data.shape[1]), importances[indices])\n",
    "            plt.xticks(range(X_data.shape[1]), names, rotation=90, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_pth, 'feature_importances.png'))\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating feature importance plot: {e}\")\n",
    "\n",
    "    def plot_shap_summary():\n",
    "        ''' Plot and save SHAP summary plot. '''\n",
    "        try:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_data)\n",
    "            shap.summary_plot(shap_values, X_data, plot_type=\"bar\", show=False)\n",
    "            plt.savefig(os.path.join(output_pth, 'shap_summary_plot.png'))\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating SHAP summary plot: {e}\")\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    ensure_dir(output_pth)\n",
    "\n",
    "    # Generate and save the plots\n",
    "    plot_feature_importances()\n",
    "    plot_shap_summary()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is your trained RandomForestClassifier or similar,\n",
    "# and `X_test` is your DataFrame of test features:\n",
    "# output_path = './images/results/'\n",
    "# feature_importance_plot(model, X_test, output_path)\n",
    "\n",
    "# Load the model using the helper function\n",
    "rfc_best = load_model(model_path)\n",
    "\n",
    "if rfc:\n",
    "    feature_importance_plot(rfc_best, X_test, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"./data/bank_data.csv\"\n",
    "output_path = './images/results/'\n",
    "model_path = './models/rfc_model.pkl'\n",
    "\n",
    "df = import_data(pth)\n",
    "perform_eda(df)\n",
    "df_encoded = encoder_helper(df, category_list)\n",
    "X_train, X_test, y_train, y_test = perform_feature_engineering(df, 'Churn')\n",
    "(y_train, y_test, y_train_preds_lr, y_train_preds_rf, y_test_preds_lr, y_test_preds_rf) = train_models(X_train, X_test, y_train, y_test)\n",
    "classification_report_image(y_train, y_test, y_train_preds_lr, y_train_preds_rf, y_test_preds_lr, y_test_preds_rf)\n",
    "\n",
    "\n",
    "# Load the model using the helper function\n",
    "rfc = load_model(model_path)\n",
    "\n",
    "if rfc:\n",
    "    feature_importance_plot(rfc, X_test, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_image(y_train, y_test, y_train_preds_lr, y_train_preds_rf, y_test_preds_lr, y_test_preds_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
